{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seedtag codetest: NLP Researcher\n",
    "\n",
    "## Part 3. Message-matcher baseline model\n",
    "This communication contains a message matcher baseline model. Given a query text message and a corpus of historical messages, this matcher model retrieves all historical messages that are similar to the queried one. Your goal is to improve this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hashlib import md5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Initialize resources\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(path, tag):\n",
    "    '''\n",
    "    Creates a data frame for a given class\n",
    "    --------------------------------------\n",
    "    Input:\n",
    "        path (str): path where all classes folders are stored.\n",
    "        tag (str): name of the folder containing class \"tag\".\n",
    "    Output:\n",
    "        df (pd.DataFrame): dataframe with file as index and columns=[text, tag]\n",
    "    '''\n",
    "    list_of_text = []\n",
    "    tag_dir = os.path.join(path, tag)\n",
    "    for file in os.listdir(tag_dir):\n",
    "\n",
    "        with open(os.path.join(tag_dir, file), encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "            list_of_text.append((text, file))\n",
    "            df = pd.DataFrame(list_of_text, columns = ['Text', 'file'])\n",
    "            df = df.set_index('file')\n",
    "    df['tag'] = tag\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_all_dfs(path, tags):\n",
    "    '''\n",
    "    Loops over all classes in path, each in the corresponding folder\n",
    "    --------------------------------\n",
    "    Input:\n",
    "        path (str): path where all classes folders are stored.\n",
    "        tags (list): list of classes names.\n",
    "    Output:\n",
    "        df (pd.DataFrame): pandas dataframe with the dataframes corresponding to all classes concatenated.\n",
    "    '''\n",
    "    list_of_dfs = []\n",
    "    for tag in tags:\n",
    "\n",
    "        df = create_df(path, tag)\n",
    "        list_of_dfs.append(df)\n",
    "    data = pd.concat(list_of_dfs)\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_md5(rsc_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert rcs_id string into a hexdigest md5.\n",
    "    :param rcs_id: str.\n",
    "    :return: hexdigext representation of md5 codification of input string.\n",
    "    \"\"\"\n",
    "    md5_rsc = bytes(rsc_id, 'utf-8')\n",
    "    result_1 = md5(md5_rsc)\n",
    "    return result_1.hexdigest()\n",
    "\n",
    "\n",
    "def get_similarity(resources: pd.DataFrame, space: str = 'tfidf', max_df: float = .75) -> np.array:\n",
    "    \"\"\"\n",
    "    Compute pairwise cosine similarity for resources in a given vector representation (tf or tfidf).\n",
    "    :param resources: pd.DataFrame with the resources as rows and at least 'Text' as column.\n",
    "    :param space: vector space representation of resources, either 'tf' or 'tfidf'.\n",
    "    :param max_df: maximum valur for document frequency just as in sklearn Vectorizers.\n",
    "    :return: symmetric np.array with cosine similarity score for each resource pair.\n",
    "    \"\"\"\n",
    "    if space == 'tf':\n",
    "        vec = CountVectorizer(min_df=2, max_df=max_df)\n",
    "    elif space == 'tfidf':\n",
    "        vec = TfidfVectorizer(min_df=2, max_df=max_df)\n",
    "    else:\n",
    "        print('The \"space\" input must be either \"tf\" or \"tfidf\", using the default \"tfidf\" option...')\n",
    "        vec = TfidfVectorizer(min_df=2, max_df=max_df)\n",
    "    vec_res = vec.fit_transform(resources['Text'].fillna(''))\n",
    "    sims = cosine_similarity(vec_res, vec_res)\n",
    "    return sims\n",
    "\n",
    "\n",
    "def find_similar_rsc(similarity_scores: np.array, threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get a dictionary relating resources to a list of [resource, score] pairs per resource.\n",
    "    :param similarity_scores: matrix of similarity score per pair of resources of shape\n",
    "    (number of resoures, number of resources).\n",
    "    :param threshold: the similarity score threshold for retrieving as similar resource.\n",
    "    :return: a pd.DataFrame with 'resource_idx', 'similar_res_idx' and 'similarity_score' as columns relating resources\n",
    "    to a given resource.\n",
    "    \"\"\"\n",
    "    similar_rsc_idx = np.where((similarity_scores >= threshold) & (similarity_scores < 0.999))\n",
    "    similar_scores = np.round(similarity_scores[similar_rsc_idx], 3)\n",
    "    sim_res = pd.DataFrame({'resource_idx': similar_rsc_idx[0],\n",
    "                            'similar_res_idx': similar_rsc_idx[1],\n",
    "                            'similarity_score': similar_scores})\n",
    "    return sim_res\n",
    "\n",
    "\n",
    "def get_similar_rsc(resources: pd.DataFrame, threshold: float = 0.75, space: str = 'tfidf') -> dict:\n",
    "    \"\"\"\n",
    "    Get similar resources per resource.\n",
    "    :param resources: pd.DataFrame with the resources as rows and at least 'Text' as column.\n",
    "    :param threshold: the similarity score threshold for retrieving as similar resource.\n",
    "    :param space: vector space representation of resources, either 'tf' or 'tfidf'.\n",
    "    :return: a dictionary with resources as keys and similar resources as values.\n",
    "    \"\"\"\n",
    "    sims = get_similarity(resources, space)\n",
    "    find_sims = find_similar_rsc(sims, threshold)\n",
    "    sim_df = find_sims.copy()\n",
    "    sim_df.reset_index(inplace=True)\n",
    "    sim_df['resource_id'] = resources['resource_id'].iloc[find_sims.resource_idx].values\n",
    "    sim_df['similar_res'] = resources['resource_id'].iloc[find_sims.similar_res_idx].values\n",
    "    sim_df['sim_resources'] = sim_df.apply(lambda x: [[x.similar_res, x.similarity_score]], axis=1)\n",
    "    grouped_sim_res = sim_df[['resource_id', 'sim_resources']].groupby('resource_id').agg(lambda x: np.sum(x))\n",
    "    similar_res_dict = grouped_sim_res.T.to_dict('records')[0]\n",
    "    sim_res = {k: sorted(v, key=lambda x: x[1], reverse=True) for k, v in similar_res_dict.items()}\n",
    "    return sim_res\n",
    "\n",
    "\n",
    "def get_similar(input_text: str, corpus: pd.DataFrame, threshold: float=0.75, space: str = 'tfidf') -> list:\n",
    "    \"\"\"\n",
    "    Retrieves a set of messages from a given corpus that are similar enough to an input message.\n",
    "    :param input_text: query text.\n",
    "    :param corpus: pd.DataFrame with historical messages as column 'Text'.\n",
    "    :param threshold: the similarity score threshold for retrieving as similar resource.\n",
    "    :param space: vector space representation of resources, either 'tf' or 'tfidf'.\n",
    "    :return: a list with all the similar messages content and corresponding score to the queried one.\n",
    "    \"\"\"\n",
    "    input_id = to_md5(input_text)\n",
    "    input_df = pd.DataFrame({'Text': [input_text], 'resource_id': [input_id]})\n",
    "    data = pd.concat([input_df, corpus])\n",
    "    sim_dict = get_similar_rsc(data, threshold, space)\n",
    "    result = list()\n",
    "    if sim_dict.get(input_id):\n",
    "        for sim_id, sim_score in sim_dict.get(input_id):\n",
    "            result.append([corpus['Text'][corpus['resource_id'] == sim_id].values[0], sim_score])\n",
    "    else:\n",
    "        result = [None, 0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess text by normalizing, removing noise, and lemmatizing.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    text : str\n",
    "        Input text string to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    cleaned_text : str\n",
    "        Processed text with noise removed, normalized, and lemmatized.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'article-i\\.d\\.: [^\\s]+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing data\n",
    "\n",
    "From a given set of messages, a historical corpus and a query message are defined. Thus, the query message is fed into the message matcher so that all messages from the corpus similar to the query one are retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../part1/dataset'\n",
    "tags = os.listdir(path)\n",
    "data_full = get_all_dfs(path, tags)[['Text']]\n",
    "data_full['resource_id'] = data_full['Text'].apply(to_md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3467, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>resource_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54357</th>\n",
       "      <td>\\nPosted by Cathy Smith for L. Neil Smith\\n\\n ...</td>\n",
       "      <td>ac22da42387cfe902642f3776b2d369b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60997</th>\n",
       "      <td>\\nIn article &lt;1r46o9INN14j@mojo.eng.umd.edu&gt; s...</td>\n",
       "      <td>ccda3081810de5243b810dbe1be2b0c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54703</th>\n",
       "      <td>\\nIn article &lt;C5D05G.6xw@undergrad.math.uwater...</td>\n",
       "      <td>f532fdae92d458e008e0353714a6a4c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51278</th>\n",
       "      <td>\\nIn &lt;1993Apr4.093904.20517@proxima.alt.za&gt; lu...</td>\n",
       "      <td>e34b0e4b6124c8c58581500def576ea1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101650</th>\n",
       "      <td>Article-I.D.: morrow.1psg9cINNn86\\n\\nIn articl...</td>\n",
       "      <td>537e88736575edfa1362bb0f12ea8c7f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "file                                                        \n",
       "54357   \\nPosted by Cathy Smith for L. Neil Smith\\n\\n ...   \n",
       "60997   \\nIn article <1r46o9INN14j@mojo.eng.umd.edu> s...   \n",
       "54703   \\nIn article <C5D05G.6xw@undergrad.math.uwater...   \n",
       "51278   \\nIn <1993Apr4.093904.20517@proxima.alt.za> lu...   \n",
       "101650  Article-I.D.: morrow.1psg9cINNn86\\n\\nIn articl...   \n",
       "\n",
       "                             resource_id  \n",
       "file                                      \n",
       "54357   ac22da42387cfe902642f3776b2d369b  \n",
       "60997   ccda3081810de5243b810dbe1be2b0c2  \n",
       "54703   f532fdae92d458e008e0353714a6a4c7  \n",
       "51278   e34b0e4b6124c8c58581500def576ea1  \n",
       "101650  537e88736575edfa1362bb0f12ea8c7f  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = data_full.sample(int(data_full.shape[0] * 0.9))\n",
    "test_data = data_full[~data_full.resource_id.isin(corpus.resource_id)]\n",
    "print(corpus.shape)\n",
    "corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file\n",
       "102723    Article-I.D.: pollux.1psvouINNa2l\\n\\n\\nThe Ang...\n",
       "38432     \\nspworley@netcom.com (Steve Worley) writes:\\n...\n",
       "61161     Article-I.D.: aurora.1993Apr23.123433.1\\n\\nIn ...\n",
       "178533    \\n(oh boy. it's the [in]famous Phill Hallam-Ba...\n",
       "38627     \\nMark A. Cartwright (markc@emx.utexas.edu) wr...\n",
       "                                ...                        \n",
       "54357     \\nPosted by Cathy Smith for L. Neil Smith\\n\\n ...\n",
       "60997     \\nIn article <1r46o9INN14j@mojo.eng.umd.edu> s...\n",
       "54703     \\nIn article <C5D05G.6xw@undergrad.math.uwater...\n",
       "51278     \\nIn <1993Apr4.093904.20517@proxima.alt.za> lu...\n",
       "101650    Article-I.D.: morrow.1psg9cINNn86\\n\\nIn articl...\n",
       "Name: Text, Length: 3467, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'Text' column has been saved to text_column_output.txt.\n"
     ]
    }
   ],
   "source": [
    "# output_file = 'text_column_output.txt'\n",
    "\n",
    "# # Open a file in write mode and save the text\n",
    "# with open(output_file, 'w', encoding='utf-8') as f:\n",
    "#     for index, row in your_dataframe.iterrows():\n",
    "#         f.write(f\"Index: {index}\\n\")\n",
    "#         f.write(f\"Text: {row['Text']}\\n\")\n",
    "#         f.write(\"-\" * 80 + \"\\n\")  # Separator between rows\n",
    "\n",
    "# print(f\"The 'Text' column has been saved to {output_file}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1) Deeper analysis in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full['cleaned_text'] = data_full['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>resource_id</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59848</th>\n",
       "      <td>Article-I.D.: cs.controversy_733694426\\n\\n\\nCO...</td>\n",
       "      <td>32701d55c7514412c8e297dc566bebc6</td>\n",
       "      <td>controversial question issue periodically come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59849</th>\n",
       "      <td>Article-I.D.: cs.groups_733694492\\n\\n\\nSPACE A...</td>\n",
       "      <td>13890b221fa3da7c82444a9c2f7d6126</td>\n",
       "      <td>space activistinterestresearch group space pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59850</th>\n",
       "      <td>Article-I.D.: cs.astronaut_733694515\\n\\n\\nHOW ...</td>\n",
       "      <td>dae3a32be9293511b5a2ad48095f039b</td>\n",
       "      <td>become astronaut first short form authored hen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59870</th>\n",
       "      <td>\\n\\nDIFFS SINCE LAST FAQ POSTING (IN POSTING O...</td>\n",
       "      <td>dde5ba372c661832f108fa0693e4a0cc</td>\n",
       "      <td>diffs since last faq posting posting order han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59873</th>\n",
       "      <td>\\n\\nONLINE AND OTHER SOURCES OF IMAGES, DATA, ...</td>\n",
       "      <td>288935f9f99377966abc786c29b0ee79</td>\n",
       "      <td>online source image data etc introduction wide...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "file                                                       \n",
       "59848  Article-I.D.: cs.controversy_733694426\\n\\n\\nCO...   \n",
       "59849  Article-I.D.: cs.groups_733694492\\n\\n\\nSPACE A...   \n",
       "59850  Article-I.D.: cs.astronaut_733694515\\n\\n\\nHOW ...   \n",
       "59870  \\n\\nDIFFS SINCE LAST FAQ POSTING (IN POSTING O...   \n",
       "59873  \\n\\nONLINE AND OTHER SOURCES OF IMAGES, DATA, ...   \n",
       "\n",
       "                            resource_id  \\\n",
       "file                                      \n",
       "59848  32701d55c7514412c8e297dc566bebc6   \n",
       "59849  13890b221fa3da7c82444a9c2f7d6126   \n",
       "59850  dae3a32be9293511b5a2ad48095f039b   \n",
       "59870  dde5ba372c661832f108fa0693e4a0cc   \n",
       "59873  288935f9f99377966abc786c29b0ee79   \n",
       "\n",
       "                                            cleaned_text  \n",
       "file                                                      \n",
       "59848  controversial question issue periodically come...  \n",
       "59849  space activistinterestresearch group space pub...  \n",
       "59850  become astronaut first short form authored hen...  \n",
       "59870  diffs since last faq posting posting order han...  \n",
       "59873  online source image data etc introduction wide...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Getting similar messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hi,\n",
      "    I was reading through \"The Spaceflight Handbook\" and somewhere in\n",
      "there the author discusses solar sails and the forces acting on them\n",
      "when and if they try to gain an initial acceleration by passing close to\n",
      "the sun in a hyperbolic orbit. The magnitude of such accelerations he\n",
      "estimated to be on the order of 700g. He also says that this is may not\n",
      "be a big problem for manned craft because humans (and this was published\n",
      "in 1986) have already withstood accelerations of 45g. All this is very\n",
      "long-winded but here's my question finally - Are 45g accelerations in\n",
      "fact humanly tolerable? - with the aid of any mechanical devices of\n",
      "course. If these are possible, what is used to absorb the acceleration?\n",
      "Can this be extended to larger accelerations?\n",
      "\n",
      "Thanks is advance...\n",
      "-Amruth Laxman\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_text = test_data.iloc[42]['Text']\n",
    "print(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Messages:\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Amruth Laxman <al26+@andrew.cmu.edu> writes:\n",
      "> Hi,\n",
      ">     I was reading through \"The Spaceflight Handbook\" and somewhere in\n",
      "> there the author discusses solar sails and the forces acting on them\n",
      "> when and if they try to gain an initial acceleration by passing close to\n",
      "> the sun in a hyperbolic orbit. The magnitude of such accelerations he\n",
      "> estimated to be on the order of 700g. He also says that this is may not\n",
      "> be a big problem for manned craft because humans (and this was published\n",
      "> in 1986) have already withstood accelerations of 45g. All this is very\n",
      "> long-winded but here's my question finally - Are 45g accelerations in\n",
      "> fact humanly tolerable? - with the aid of any mechanical devices of\n",
      "> course. If these are possible, what is used to absorb the acceleration?\n",
      "> Can this be extended to larger accelerations?\n",
      "\n",
      "are you sure 45g is the right number? as far as i know, pilots are\n",
      "blackout in dives that exceed 8g - 9g. 45g seems to be out of human\n",
      "tolerance. would anybody clarify this please.\n",
      "\n",
      "lan\n",
      "\n",
      "\n",
      "> \n",
      "> Thanks is advance...\n",
      "> -Amruth Laxman\n",
      "> \n",
      "\n",
      "Similarity score: 0.911\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "In article <EfpX7WS00Uh7QAoP1S@andrew.cmu.edu> Amruth Laxman <al26+@andrew.cmu.edu> writes:\n",
      ">... here's my question finally - Are 45g accelerations in\n",
      ">fact humanly tolerable? - with the aid of any mechanical devices of\n",
      ">course. If these are possible, what is used to absorb the acceleration?\n",
      "\n",
      "This sounds a bit high to me.  Still higher accelerations have been endured\n",
      "*very briefly*, during violent deceleration.  If we're talking sustained\n",
      "acceleration, I think 30-odd gees has been demonstrated using water immersion.\n",
      "\n",
      "I doubt that any of this generalizes to another order of magnitude.\n",
      "-- \n",
      "All work is one man's work.             | Henry Spencer @ U of Toronto Zoology\n",
      "                    - Kipling           |  henry@zoo.toronto.edu  utzoo!henry\n",
      "\n",
      "Similarity score: 0.485\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "similar_results = get_similar(query_text, corpus, 0.2)\n",
    "if similar_results[0]:\n",
    "    print(\"Similar Messages:\")\n",
    "    for result in similar_results:\n",
    "        print(\"-\"*75)\n",
    "        print(result[0])\n",
    "        print(f\"Similarity score: {result[1]}\")\n",
    "        print(\"-\"*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Using Embeddings for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_seedtag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
